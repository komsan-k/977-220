# üî¨ Lab 14: High-Level Synthesis (HLS) and AI Accelerator Integration in FPGA Systems

## üß© 1. Objective
This laboratory explores **High-Level Synthesis (HLS)** workflows and **AI hardware acceleration** on FPGA platforms.  
Students will learn to:
- Develop computational accelerators using **C/C++ or Python (PYNQ)**.  
- Integrate **HLS-generated IP blocks** into Verilog SoC systems.  
- Implement a **Matrix Multiply / Neural Inference Engine** on FPGA.  
- Compare **RTL-based vs. HLS-based** design performance.  

---

## ‚öôÔ∏è 2. Equipment and Tools
| Tool / Resource | Description |
|------------------|-------------|
| **Xilinx Vitis HLS** | High-Level Synthesis environment |
| **Vivado / ModelSim** | Integration and verification |
| **FPGA board (Zybo / Nexys A7 / PYNQ-Z2)** | Hardware platform |
| **C/C++ Compiler / Python (PYNQ Jupyter)** | Host control |
| **AXI-Lite Interface** | Communication with SoC CPU (MicroBlaze or ARM) |

---

## üß† 3. Background Theory

### 3.1 High-Level Synthesis (HLS)
HLS allows designers to describe hardware in **C/C++**, which is automatically converted into RTL code (Verilog/VHDL).  
This reduces design complexity and enables algorithmic exploration.

#### Basic HLS Flow
1. Write algorithm in **C/C++**.  
2. Add **synthesis directives** (`#pragma HLS`) for optimization.  
3. Generate **Verilog IP core**.  
4. Integrate IP into FPGA SoC using **AXI interfaces**.

### 3.2 AI Accelerator Concept
A **Neural Network Processing Unit (NPU)** executes matrix-vector operations and activations.  
This structure is ideal for FPGA due to **massive parallelism**.

Simplified block:
```
Inputs  ‚Üí  Multiply‚ÄìAccumulate Array  ‚Üí  Activation (ReLU/Sigmoid)  ‚Üí  Output
```

---

## ‚öôÔ∏è 4. HLS Module Design (Matrix Multiplication Example)

### 4.1 C Code for HLS Accelerator
```c
#include "ap_int.h"

#define N 4

void matmul_accel(ap_int<8> A[N][N], ap_int<8> B[N][N], ap_int<16> C[N][N]) {
#pragma HLS PIPELINE
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            ap_int<16> sum = 0;
            for (int k = 0; k < N; k++) {
#pragma HLS UNROLL
                sum += A[i][k] * B[k][j];
            }
            C[i][j] = sum;
        }
    }
}
```

### 4.2 HLS Directive Summary
| Directive | Function |
|------------|-----------|
| `#pragma HLS PIPELINE` | Enables concurrent loop execution. |
| `#pragma HLS UNROLL` | Fully expands inner loops for parallel multiply‚Äìaccumulate. |
| `#pragma HLS INTERFACE m_axi` | Generates AXI interfaces for external memory access. |

### 4.3 Generated Verilog Wrapper (Simplified)
```verilog
module matmul_accel (
  input ap_clk,
  input ap_rst,
  input ap_start,
  output ap_done,
  input [7:0] A_0, B_0,
  output [15:0] C_0
);
// Generated by Vitis HLS ‚Äì computation mapped to DSP slices
endmodule
```

---

## üß© 5. Verilog SoC Integration
Once the IP is generated by HLS, it can be instantiated into an existing SoC (from **Lab 12/13**).

```verilog
module SoC_AI(
  input clk, rst,
  input [7:0] addr, din,
  input we, re,
  output [15:0] dout
);
  wire sel_hls;
  assign sel_hls = (addr[7:4] == 4'h4); // Address range 0x40‚Äì0x4F

  wire done;
  matmul_accel hls_core (
    .ap_clk(clk),
    .ap_rst(rst),
    .ap_start(we & sel_hls),
    .ap_done(done)
  );
endmodule
```

---

## üßÆ 6. Host Control (Python on PYNQ Board)
```python
from pynq import Overlay, allocate
import numpy as np

overlay = Overlay("soc_ai.bit")
matmul = overlay.matmul_accel_0

A = np.array([[1,2,3,4],[4,3,2,1],[1,0,1,0],[0,1,0,1]], dtype=np.int8)
B = np.array([[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]], dtype=np.int8)
C = np.zeros((4,4), dtype=np.int16)

matmul.call(A, B, C)
print("Matrix C Result:\n", C)
```

---

## üìä 7. Observation Table
| Input A (4√ó4) | Input B (4√ó4) | Output C (4√ó4) | Time (¬µs) | Speedup |
|----------------|----------------|----------------|------------|----------|
| Random | Random | Correct | 3.5 | 12√ó faster than C loop |

---

## üí° 8. Discussion Points
- How do **HLS pipelines** improve performance compared to Verilog RTL?  
- What are the **limitations of HLS** (latency, synthesis control)?  
- Why is **AXI-Lite** important for IP‚ÄìSoC communication?  
- Compare **manual RTL** vs **HLS auto-generated** designs for efficiency.  

---

## üß† 9. Post-Lab Exercises
1. Implement a **3√ó3 convolution** kernel for CNNs.  
2. Integrate **sigmoid/tanh activation** logic in hardware.  
3. Add a **DMA controller** for fast data transfer.  
4. Profile FPGA utilization for **different unroll factors**.  
5. Compare **FPGA vs CPU** computation performance.  

---

## üßæ 10. Outcome
Students will be able to:
- Develop and synthesize accelerators using **HLS C/C++**.  
- Integrate **HLS IPs** within Verilog SoC architectures.  
- Validate **AI computation** on FPGA boards.  
- Compare **RTL vs HLS** trade-offs in performance and area.  

---

## üìò 11. References
1. Xilinx, *Vitis HLS User Guide (UG1399)*  
2. Xilinx, *PYNQ Framework Documentation*  
3. Pong P. Chu, *FPGA Prototyping by Verilog Examples*  
4. Samir Palnitkar, *Verilog HDL: A Guide to Digital Design and Synthesis*  
5. D. Harris & S. Harris, *Digital Design and Computer Architecture (ARM Edition)*  

---

**Author:** Dr. Komsan Kanjanasit  
**Publisher:** College of Computing, Prince of Songkla University, Thailand  
**Edition:** First Edition (2025)  
**License:** CC BY 4.0 ‚Äî Free to use with attribution
